{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using tf.similarity on iris dataset\n",
    "\n",
    "This tutorial uses tf.similiarity package to show how we can use tf.similarity on the iris dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell if you want to suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from absl import app, flags\n",
    "from tensorflow_similarity.api.engine.simhash import SimHash\n",
    "from tensorflow_similarity.api.engine.augmentation import Augmentation\n",
    "import numpy as np\n",
    "import six\n",
    "import tabulate\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check tensorflow version, it should be 2.x\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "!pip install --upgrade keras-tuner\n",
    "import kerastuner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relative datapath to the downloaded iris dataset\n",
    "DEFAULT_IRIS_DATA_PATH = \"iris.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_iris_data(data_path):\n",
    "    \"\"\" Returns the iris data.\n",
    "    \n",
    "    Opens the data file specified by the argument, read each\n",
    "    line and puts 20% of the data into the testing set.\n",
    "    \n",
    "    Args:\n",
    "        data_path: A string that points to the iris dataset.\n",
    "    \n",
    "    Returns:\n",
    "        A tuple that contains two elements. The first element\n",
    "        is a tuple that contains data used for training and\n",
    "        the second element is a tuple that contains data used\n",
    "        for testing. Both of those two tuples have the same\n",
    "        structure, they both contains two elements. The first\n",
    "        element contains a dictionary for the specs of iris\n",
    "        flowers (in 2d np array), the second element contains\n",
    "        an np array of labels of class.\n",
    "        For example:\n",
    "        \n",
    "        (\n",
    "          ({'example': [[0,1,3,4],[2,1,3,5]]}, [0,2]),\n",
    "          ({'example': [[0,2,3,5],[2,1,4,5]]}, [1,2])\n",
    "        )\n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.io.gfile.GFile(data_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        x_train = []\n",
    "        y_train = []\n",
    "        x_test = []\n",
    "        y_test = []\n",
    "        for idx, line in enumerate(lines):\n",
    "            tokens = line.split(\",\")\n",
    "            y = int(tokens[-1])\n",
    "            x = [float(i) for i in tokens[:-1]]\n",
    "\n",
    "            if idx % 10 == 0:\n",
    "                x_test.append(x)\n",
    "                y_test.append(y)\n",
    "            else:\n",
    "                x_train.append(x)\n",
    "                y_train.append(y)\n",
    "\n",
    "        x_train = {\"example\": np.array(x_train)}\n",
    "        x_test = {\"example\": np.array(x_test)}\n",
    "\n",
    "        return ((x_train, np.array(y_train)), (x_test, np.array(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_targets(x_test, y_test):\n",
    "    \"\"\"Creates targets from the test dataset.\n",
    "    \n",
    "    First we group the data by the labels (the value in y_test),\n",
    "    then for each labels we compute the mean of the data.\n",
    "    \n",
    "    Args:\n",
    "        x_test: A dictionary that contains a single key\n",
    "            with the value of an 2d np array. For example,\n",
    "            {\"example\": [[1,3,4,2], [2,1,4,7]]}\n",
    "        y_test: A 1d np array containing the classification.\n",
    "            For example,\n",
    "            [0,1]\n",
    "    \n",
    "    Returns:\n",
    "        x_targets: A dictionary that contains a single key\n",
    "            with the value of an 2d np array. The length of\n",
    "            the np array should be the number of classes.\n",
    "        y_targets: A 1d np array ocntaining the classification.\n",
    "    \"\"\"\n",
    "    \n",
    "    by_label = {0: [], 1: [], 2: []}\n",
    "\n",
    "    for x, y in zip(x_test[\"example\"], y_test):\n",
    "        by_label[y].append(x)\n",
    "\n",
    "    x_targets = []\n",
    "    y_targets = []\n",
    "\n",
    "    for label, data in six.iteritems(by_label):\n",
    "        mean = np.mean(data, axis=0)\n",
    "        x_targets.append(mean)\n",
    "        y_targets.append(label)\n",
    "    x_targets = np.array(x_targets)\n",
    "    x_targets = {\"example\": x_targets}\n",
    "    y_targets = np.array(y_targets)\n",
    "\n",
    "    return x_targets, y_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iris_data():\n",
    "    \"\"\"Computes and returns the training, testing, and target datasets.\"\"\"\n",
    "    \n",
    "    (x_train, y_train), (x_test, y_test) = read_iris_data(DEFAULT_IRIS_DATA_PATH)\n",
    "    (x_targets, y_targets) = create_targets(x_test, y_test)\n",
    "    return (x_train, y_train), (x_test, y_test), (x_targets, y_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define tower models and custom augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_model():\n",
    "    \"\"\"A simple tower model for iris dataset.\n",
    "    \n",
    "    Returns:\n",
    "        model: A tensorflow model that has 3 hidden\n",
    "            layers that has 10, 8, 6 neurons\n",
    "            respectively.         \n",
    "    \"\"\"\n",
    "    \n",
    "    i = Input(shape=(4,), name='example')\n",
    "    o = Dense(10, activation='tanh')(i)\n",
    "    o = Dense(8, activation='tanh')(o)\n",
    "    o = Dense(6, activation='tanh')(o)\n",
    "    o = Dense(3)(o)\n",
    "    model = Model(i, o)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fuzz(Augmentation):\n",
    "    \"\"\"An Augmentation class that disturbed the data.\"\"\"\n",
    "    \n",
    "    def augment(self, x):\n",
    "        \"\"\"Returns disturbed data.\"\"\"\n",
    "        \n",
    "        x = x[\"example\"]\n",
    "\n",
    "        FUZZ = .01\n",
    "        fuzz = np.random.random_sample(x.shape) * FUZZ - FUZZ / 2.0\n",
    "\n",
    "        x = x - fuzz\n",
    "        return {\"example\": x}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_metrics(train_metrics, test_metrics):\n",
    "    unpacked_train_metrics = [(i[0], i[1]) for i in six.iteritems(train_metrics)]\n",
    "    unpacked_test_metrics = [(i[0], i[1]) for i in six.iteritems(test_metrics)]\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"TRAINING\")\n",
    "    print(tabulate.tabulate(unpacked_train_metrics, [\"Metric\", \"Value\"]))\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"TEST\")\n",
    "    print(tabulate.tabulate(unpacked_test_metrics, [\"Metric\", \"Value\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example usage 1: basic usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_similarity_run(data, strategy, tower_model, epochs):\n",
    "    \"\"\"A basic example usage of tf.similarity using iris dataset.\n",
    "    \n",
    "    This basic similarity run will first unpackage training,\n",
    "    testing, and target data from the arguments and then construct a\n",
    "    simple moirai model, fit the model with training data, then\n",
    "    evaluate our model with training and testing datasets.\n",
    "    \n",
    "    Args:\n",
    "        data: Sets, contains training, testing, and target datasets.\n",
    "        strategy: String, specify the strategy to use for mining triplets.\n",
    "        tower_model: tf.Model, the tower model to fit into moirai.\n",
    "        epochs: Integer, number of epochs to fit our moirai model.\n",
    "        callbacks: List of callback functions, \n",
    "    \n",
    "    Returns:\n",
    "        moirai_model: SimHash\n",
    "        train_metrics: Dictionary, containing metrics performed on the\n",
    "            training dataset. The key is the name of the metric and the\n",
    "            value is the np array of the metric values.\n",
    "        test_metrics: Dictionary, containing metrics performed on the\n",
    "            testing dataset. The key is the name of the metric and the\n",
    "            value is the np array of the metric values.\n",
    "    \"\"\"\n",
    "    \n",
    "    # unpackage data\n",
    "    (x_train, y_train), (x_test, y_test), (x_targets, y_targets) = data\n",
    "\n",
    "    print(\"Initial tower model summary:\")\n",
    "    tower_model.summary()\n",
    "\n",
    "    moirai_model = SimHash(\n",
    "        tower_model,\n",
    "        augmentation=Fuzz(),\n",
    "        optimizer=Adam(lr=0.001),\n",
    "        strategy=strategy)\n",
    "\n",
    "    early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"loss\", mode='min', min_delta=0.00000001, patience=50)\n",
    "    \n",
    "    callbacks = [early_stopping_callback]\n",
    "    \n",
    "    moirai_model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        epochs=epochs,\n",
    "        verbose=1,\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "    \n",
    "    train_metrics = moirai_model.evaluate(x_train, y_train, x_targets, y_targets)\n",
    "    test_metrics = moirai_model.evaluate(x_test, y_test, x_targets, y_targets)\n",
    "    \n",
    "    return moirai_model, train_metrics, test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_iris_data()\n",
    "tower_model = simple_model()\n",
    "strategy = \"hard_quadruplet_loss\"\n",
    "epochs = 5\n",
    "\n",
    "basic_moirai_model, train_metrics, test_metrics = basic_similarity_run(data, strategy, tower_model, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_metrics(train_metrics, test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example usage 2: With Visualization Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional imports\n",
    "import datetime\n",
    "from tensorflow_similarity.api.callbacks.metrics_callbacks import MetricsCallback\n",
    "from tensorflow_similarity.api.callbacks.plugins import ConfusionMatrixCallbackPlugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run the below line to clear any logs from previous runs\n",
    "!rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_run_with_visualization(data, strategy, tower_model, epochs):\n",
    "    \"\"\"A basic example usage of tf.similarity using iris dataset with visualization callbacks.\n",
    "    \n",
    "    This basic similarity run will first unpackage training,\n",
    "    testing, and target data from the arguments and then construct a\n",
    "    simple moirai model, fit the model with training data, then\n",
    "    evaluate our model with training and testing datasets.\n",
    "    \n",
    "    Args:\n",
    "        data: Sets, contains training, testing, and target datasets.\n",
    "        strategy: String, specify the strategy to use for mining triplets.\n",
    "        tower_model: tf.Model, the tower model to fit into moirai.\n",
    "        epochs: Integer, number of epochs to fit our moirai model.\n",
    "        callbacks: List of callback functions, \n",
    "    \n",
    "    Returns:\n",
    "        moirai_model: SimHash\n",
    "        train_metrics: Dictionary, containing metrics performed on the\n",
    "            training dataset. The key is the name of the metric and the\n",
    "            value is the np array of the metric values.\n",
    "        test_metrics: Dictionary, containing metrics performed on the\n",
    "            testing dataset. The key is the name of the metric and the\n",
    "            value is the np array of the metric values.\n",
    "    \"\"\"\n",
    "    \n",
    "    # unpackage data\n",
    "    (x_train, y_train), (x_test, y_test), (x_targets, y_targets) = data\n",
    "\n",
    "    print(\"Initial tower model summary:\")\n",
    "    tower_model.summary()\n",
    "\n",
    "    moirai_model = SimHash(\n",
    "        tower_model,\n",
    "        augmentation=Fuzz(),\n",
    "        optimizer=Adam(lr=0.001),\n",
    "        strategy=strategy)\n",
    "\n",
    "    early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"loss\", mode='min', min_delta=0.00000001, patience=50)\n",
    "    \n",
    "    log_dir=\"logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    confusion_matrix_log_dir = log_dir + \"/confusion_matrix\"\n",
    "    \n",
    "    confusion_matrix_plugin = ConfusionMatrixCallbackPlugin(confusion_matrix_log_dir)\n",
    "    metrics_callbacks = MetricsCallback(\n",
    "        [confusion_matrix_plugin],\n",
    "        x_test,\n",
    "        y_test,\n",
    "        x_targets,\n",
    "        y_targets)\n",
    "    \n",
    "    callbacks = [early_stopping_callback, metrics_callbacks]\n",
    "    \n",
    "    moirai_model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        epochs=epochs,\n",
    "        verbose=1,\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "    \n",
    "    train_metrics = moirai_model.evaluate(x_train, y_train, x_targets, y_targets)\n",
    "    test_metrics = moirai_model.evaluate(x_test, y_test, x_targets, y_targets)\n",
    "    \n",
    "    return moirai_model, train_metrics, test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_iris_data()\n",
    "tower_model = simple_model()\n",
    "strategy = \"hard_quadruplet_loss\"\n",
    "epochs = 5\n",
    "\n",
    "basic_moirai_model, train_metrics, test_metrics = similarity_run_with_visualization(data, strategy, tower_model, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_metrics(train_metrics, test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
